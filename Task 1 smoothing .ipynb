{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d03251",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d3f6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/kaengreg/.local/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/kaengreg/.local/lib/python3.10/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/kaengreg/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746b03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28c9923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Words  Probabilities\n",
      "0        вот       0.035088\n",
      "1        кот       0.017544\n",
      "2    который       0.052632\n",
      "3     пугает       0.017544\n",
      "4          и       0.017544\n",
      "5      ловит       0.017544\n",
      "6     синицу       0.017544\n",
      "7    которая       0.052632\n",
      "8      часто       0.035088\n",
      "9     ворует       0.035088\n",
      "10   пшеницу       0.035088\n",
      "11         в       0.052632\n",
      "12    тёмном       0.035088\n",
      "13    чулане       0.035088\n",
      "14  хранится       0.035088\n",
      "15      доме       0.035088\n",
      "16  построил       0.035088\n",
      "17      джек       0.035088\n",
      "\n",
      "       Words  Probabilities\n",
      "0        вот       0.029268\n",
      "1        кот       0.004878\n",
      "2    который       0.053659\n",
      "3     пугает       0.004878\n",
      "4          и       0.004878\n",
      "5      ловит       0.004878\n",
      "6     синицу       0.004878\n",
      "7    которая       0.053659\n",
      "8      часто       0.029268\n",
      "9     ворует       0.029268\n",
      "10   пшеницу       0.029268\n",
      "11         в       0.053659\n",
      "12    тёмном       0.029268\n",
      "13    чулане       0.029268\n",
      "14  хранится       0.029268\n",
      "15      доме       0.029268\n",
      "16  построил       0.029268\n",
      "17      джек       0.029268\n",
      "\n",
      "       Words  Probabilities\n",
      "0        вот       0.033333\n",
      "1        кот       0.013725\n",
      "2    который       0.052941\n",
      "3     пугает       0.013725\n",
      "4          и       0.013725\n",
      "5      ловит       0.013725\n",
      "6     синицу       0.013725\n",
      "7    которая       0.052941\n",
      "8      часто       0.033333\n",
      "9     ворует       0.033333\n",
      "10   пшеницу       0.033333\n",
      "11         в       0.052941\n",
      "12    тёмном       0.033333\n",
      "13    чулане       0.033333\n",
      "14  хранится       0.033333\n",
      "15      доме       0.033333\n",
      "16  построил       0.033333\n",
      "17      джек       0.033333\n",
      "\n",
      "                  Words  Probabilities\n",
      "0            (вот, дом)       1.000000\n",
      "1        (дом, который)       1.000000\n",
      "2   (который, построил)       1.000000\n",
      "3      (построил, джек)       1.000000\n",
      "4             (джек, а)       0.666667\n",
      "5              (а, это)       1.000000\n",
      "6        (это, пшеница)       0.500000\n",
      "7    (пшеница, которая)       1.000000\n",
      "8          (которая, в)       0.666667\n",
      "9           (в, тёмном)       0.500000\n",
      "10     (тёмном, чулане)       1.000000\n",
      "11   (чулане, хранится)       1.000000\n",
      "12        (хранится, в)       1.000000\n",
      "13            (в, доме)       0.500000\n",
      "14      (доме, который)       1.000000\n",
      "15       (это, весёлая)       0.500000\n",
      "16     (весёлая, птица)       1.000000\n",
      "17      (птица, синица)       1.000000\n",
      "18    (синица, которая)       1.000000\n",
      "19     (которая, часто)       0.333333\n",
      "20      (часто, ворует)       1.000000\n",
      "21    (ворует, пшеницу)       1.000000\n",
      "22   (пшеницу, которая)       1.000000\n",
      "\n",
      "                  Words  Probabilities\n",
      "0            (вот, кот)       0.002500\n",
      "1        (кот, который)       0.002500\n",
      "2     (который, пугает)       0.002500\n",
      "3           (пугает, и)       0.002500\n",
      "4            (и, ловит)       0.002500\n",
      "5       (ловит, синицу)       0.002500\n",
      "6     (синицу, которая)       0.002500\n",
      "7      (которая, часто)       0.004975\n",
      "8       (часто, ворует)       0.004988\n",
      "9     (ворует, пшеницу)       0.004988\n",
      "10   (пшеницу, которая)       0.004988\n",
      "11         (которая, в)       0.004975\n",
      "12          (в, тёмном)       0.004975\n",
      "13     (тёмном, чулане)       0.004988\n",
      "14   (чулане, хранится)       0.004988\n",
      "15        (хранится, в)       0.004988\n",
      "16            (в, доме)       0.004975\n",
      "17      (доме, который)       0.004988\n",
      "18  (который, построил)       0.004975\n",
      "19     (построил, джек)       0.004988\n",
      "\n",
      "                  Words  Probabilities\n",
      "0            (вот, кот)       0.027778\n",
      "1        (кот, который)       0.027778\n",
      "2     (который, пугает)       0.027778\n",
      "3           (пугает, и)       0.027778\n",
      "4            (и, ловит)       0.027778\n",
      "5       (ловит, синицу)       0.027778\n",
      "6     (синицу, которая)       0.027778\n",
      "7      (которая, часто)       0.130435\n",
      "8       (часто, ворует)       0.146341\n",
      "9     (ворует, пшеницу)       0.146341\n",
      "10   (пшеницу, которая)       0.146341\n",
      "11         (которая, в)       0.130435\n",
      "12          (в, тёмном)       0.130435\n",
      "13     (тёмном, чулане)       0.146341\n",
      "14   (чулане, хранится)       0.146341\n",
      "15        (хранится, в)       0.146341\n",
      "16            (в, доме)       0.130435\n",
      "17      (доме, который)       0.146341\n",
      "18  (который, построил)       0.130435\n",
      "19     (построил, джек)       0.146341\n",
      "\n",
      "                  Words  Probabilities\n",
      "0            (вот, кот)       0.027778\n",
      "1        (кот, который)       0.027778\n",
      "2     (который, пугает)       0.027778\n",
      "3           (пугает, и)       0.027778\n",
      "4            (и, ловит)       0.027778\n",
      "5       (ловит, синицу)       0.027778\n",
      "6     (синицу, которая)       0.027778\n",
      "7      (которая, часто)       0.062500\n",
      "8       (часто, ворует)       0.064885\n",
      "9     (ворует, пшеницу)       0.064885\n",
      "10   (пшеницу, которая)       0.064885\n",
      "11         (которая, в)       0.062500\n",
      "12          (в, тёмном)       0.062500\n",
      "13     (тёмном, чулане)       0.064885\n",
      "14   (чулане, хранится)       0.064885\n",
      "15        (хранится, в)       0.064885\n",
      "16            (в, доме)       0.062500\n",
      "17      (доме, который)       0.064885\n",
      "18  (который, построил)       0.062500\n",
      "19     (построил, джек)       0.064885\n",
      "\n",
      "Unigrams Perplexity:\n",
      "Laplasian -  19.657477821544756\n",
      "Lyambda1 -  28.98576129852453\n",
      "Lyambda2 -  21.337917028795548\n",
      "\n",
      "Bigrams Perplexity:\n",
      "Laplasian -  255.48520890907966\n",
      "Lyambda1 -  12.58086676661216\n",
      "Lyambda2 -  20.935185766090235\n"
     ]
    }
   ],
   "source": [
    "learning = open('Learning', 'r')  # learning dataset\n",
    "\n",
    "testing = open('Testing', 'r')  # testing dataset\n",
    "# ------------Preparing text----------------------\n",
    "raw_text_learn = learning.read().lower()\n",
    "text_learn = raw_text_learn.replace(\"-\", \" \")\n",
    "text_cleaned_learn = re.sub(r'[^\\w\\s]', '', text_learn)\n",
    "learn_split = text_cleaned_learn.split()  # text splitted on words\n",
    "\n",
    "unique_learn = list(set(learn_split))  # list of unique words\n",
    "\n",
    "raw_text_test = testing.read().lower()\n",
    "text_test = raw_text_test.replace(\"-\", \" \")\n",
    "text_cleaned_test = re.sub(r'[^\\w\\s]', '', text_test)\n",
    "test_split = text_cleaned_test.split()\n",
    "\n",
    "unique_test = list(set(test_split))\n",
    "\n",
    "lyambda1 = 0.2\n",
    "lyambda2 = 0.7\n",
    "# ----------------------Unigrams on learning text----------------------------\n",
    "basic_freq, basic_words = [], []\n",
    "\n",
    "for word in unique_learn:\n",
    "    word_count = 0\n",
    "    basic_words.append(word)\n",
    "    for word2 in learn_split:\n",
    "        if (word == word2):\n",
    "            word_count += 1\n",
    "    basic_freq.append(word_count / len(learn_split))\n",
    "\n",
    "uniDF = pd.DataFrame(data={'Words': unique_learn, 'Probabilities': basic_freq})\n",
    "# print(uniDF)\n",
    "\n",
    "n = len(learn_split)\n",
    "v = len(unique_learn)\n",
    "test = Counter(test_split)\n",
    "\n",
    "# ---------------------Unigrams smoothing on testing text---------------------\n",
    "uni_words, lapl_freq, lmbd1_freq, lmbd2_freq = [], [], [], []\n",
    "for word, freq in zip(test.keys(), test.values()):\n",
    "    uni_words.append(word)\n",
    "    if word in learn_split:\n",
    "        lapl_freq.append((freq + 1) / (n + v))\n",
    "        lmbd1_freq.append((freq + lyambda1) / (n + v * lyambda1))\n",
    "        lmbd2_freq.append((freq + lyambda2) / (n + v * lyambda2))\n",
    "\n",
    "    else:\n",
    "        lapl_freq.append(1 / (n + v))\n",
    "        lmbd1_freq.append(lyambda1 / (n + v * lyambda1))\n",
    "        lmbd2_freq.append(lyambda2 / (n + v * lyambda2))\n",
    "\n",
    "laplDF = pd.DataFrame(data={'Words': uni_words, 'Probabilities': lapl_freq})\n",
    "print(laplDF)\n",
    "print()\n",
    "\n",
    "lmbd1DF = pd.DataFrame(data={'Words': uni_words, 'Probabilities': lmbd1_freq})\n",
    "print(lmbd1DF)\n",
    "print()\n",
    "\n",
    "lmbd2DF = pd.DataFrame(data={'Words': uni_words, 'Probabilities': lmbd2_freq})\n",
    "print(lmbd2DF)\n",
    "print()\n",
    "\n",
    "# ----------------------------Bigrams on learning text---------------------------\n",
    "learn_bigrams = list(ngrams(learn_split, 2))\n",
    "learn_unigrams = list(ngrams(learn_split, 1))\n",
    "\n",
    "bi_basic_freq = []\n",
    "\n",
    "bigrams = Counter(learn_bigrams)\n",
    "unigrams = Counter(learn_unigrams)\n",
    "\n",
    "for bigram in bigrams:\n",
    "    for unigram in unigrams:\n",
    "        if (bigram[0] == unigram[0]):\n",
    "            bi_basic_freq.append(bigrams[bigram] / unigrams[unigram])\n",
    "\n",
    "biDF = pd.DataFrame(data={'Words': list(bigrams.keys()), 'Probabilities': bi_basic_freq})\n",
    "print(biDF)\n",
    "print()\n",
    "# ----------------------Bigrams smooting on testing text---------------------------\n",
    "b = len(learn_bigrams)\n",
    "\n",
    "test_bigrams = list(ngrams(test_split, 2))\n",
    "test_unigrams = list(ngrams(test_split, 1))\n",
    "\n",
    "bigrams_learn = Counter(learn_bigrams)\n",
    "unigrams_learn = Counter(learn_unigrams)\n",
    "bigrams_test = Counter(test_bigrams)\n",
    "unigrams_test = Counter(test_unigrams)\n",
    "\n",
    "bi_words, bi_lapl_freq, bi_lmbd1_freq, bi_lmbd2_freq = [], [], [], []\n",
    "for bigram, freq in zip(bigrams_test.keys(), bigrams_test.values()):\n",
    "    for unigram in unigrams_test.keys():\n",
    "        if bigram[0] == unigram[0]:\n",
    "            bi_words.append(bigram)\n",
    "            if bigram in bigrams_learn:\n",
    "                bi_lapl_freq.append((bigrams_test[bigram] + 1) / (unigrams_test[unigram] + v ** 2))\n",
    "                bi_lmbd1_freq.append((bigrams_test[bigram] + lyambda1) / (unigrams_test[unigram] + b * lyambda1))\n",
    "                bi_lmbd2_freq.append((bigrams_test[bigram] + lyambda2) / (unigrams_test[unigram] + b * lyambda2))\n",
    "\n",
    "            else:\n",
    "                bi_lapl_freq.append(1 / (v ** 2))\n",
    "                bi_lmbd1_freq.append(lyambda1 / (b * lyambda1))\n",
    "                bi_lmbd2_freq.append(lyambda2 / (b * lyambda2))\n",
    "\n",
    "bi_laplDF = pd.DataFrame(data={'Words': bi_words, 'Probabilities': bi_lapl_freq})\n",
    "print(bi_laplDF)\n",
    "print()\n",
    "\n",
    "bi_lmbd1DF = pd.DataFrame(data={'Words': bi_words, 'Probabilities': bi_lmbd1_freq})\n",
    "print(bi_lmbd1DF)\n",
    "print()\n",
    "\n",
    "bi_lmbd2DF = pd.DataFrame(data={'Words': bi_words, 'Probabilities': bi_lmbd2_freq})\n",
    "print(bi_lmbd2DF)\n",
    "print()\n",
    "# --------------------------Perplexity---------------------------------------------\n",
    "\n",
    "lapl_perp = (1 / np.prod(laplDF['Probabilities'])) ** (1 / len(test_split))\n",
    "lmbd1_perp = (1 / np.prod(lmbd1DF['Probabilities'])) ** (1 / len(test_split))\n",
    "lmbd2_perp = (1 / np.prod(lmbd2DF['Probabilities'])) ** (1 / len(test_split))\n",
    "\n",
    "print(\"Unigrams Perplexity:\")\n",
    "print(\"Laplasian - \", lapl_perp)\n",
    "print(\"Lyambda1 - \", lmbd1_perp)\n",
    "print(\"Lyambda2 - \", lmbd2_perp)\n",
    "\n",
    "bi_lapl_perp = (1 / np.prod(bi_laplDF['Probabilities'])) ** (1 / len(test_bigrams))\n",
    "bi_lmbd1_perp = (1 / np.prod(bi_lmbd1DF['Probabilities'])) ** (1 / len(test_bigrams))\n",
    "bi_lmbd2_perp = (1 / np.prod(bi_lmbd2DF['Probabilities'])) ** (1 / len(test_bigrams))\n",
    "\n",
    "print()\n",
    "print(\"Bigrams Perplexity:\")\n",
    "print(\"Laplasian - \", bi_lapl_perp)\n",
    "print(\"Lyambda1 - \", bi_lmbd1_perp)\n",
    "print(\"Lyambda2 - \", bi_lmbd2_perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7126f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
